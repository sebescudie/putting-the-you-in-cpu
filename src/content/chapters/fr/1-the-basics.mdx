---
chapter: 1
title: Les “bases”
shortname: Bases
slug: les-bases
updatedAt: 2023-07-19T18:57:54.630Z
---

Le truc qui m'a constamment surpris en écrivant cet article, c'est à quel point les ordinateurs sont *simples*. C'est toujours compliqué pour moi de pas me prendre la tête, en m'attendant à quelque chose de plus compliqué ou abstrait que ça l'est en réalité! S'il y a une chose à vous enfoncer dans le crâne avant de continuer, c'est que les choses qui semblent simples le sont vraiment. Cette simplicité est très belle et parfois très, très ?????

Commençons par les bases sur le fonctionnement de votre ordinateur, au plus profond.

## Comment les ordinateurs sont architecturés

Le *processeur* (en anglais CPU, *central processing unit*) d'un ordinateur s'occupe de tous les calculs. C'est le big boss. Il commence à cravacher dès que vous allumez votre ordinateur, en exécutant instruction après instruction. 

Le premier processeur produit en masse était l'[Intel 4004](http://www.intel4004.com/), conçu à la fin des années 60 par un physicien et ingénieur Italien nommé Federico Faggin. Il utilisait une architecture 4-bit, à la différence des systèmes [64-bit]https://fr.wikipedia.org/wiki/Processeur_64_bits) qu'on utilise aujourd'hui, et était bien moins complexe que les processeurs modernes, mais une grande partie de sa simplicité est toujours d'actualité.

Les "instructions" exécutées par le CPU sont juste des données binaires : un octet ou deux pour représenter l'instruction qui s’exécute (l'opcode), suivi par les données nécessaires à son exécution. Ce qu'on appelle le *code machine* n'est rien d'autre qu'une série de ces instructions binaires à la suite. L'[assembleur](https://fr.wikipedia.org/wiki/Assembleur) est une syntaxe bien pratique pour lire et écrire du code machine. Elle est plus facile à lire et écrire pour des humains que des bits bruts; et est toujours compilée en code binaire que votre CPU saura lire.

<img src='/images/assembly-to-machine-code-translation.png' loading='eager' style='max-width: 400px;' alt='Un diagramme montrant comment le code machine est converti en assembleur, et à nouveau en code machine. Une flèche bi-directionnelle connecte trois exemples : du code machine (binaire) suivi par trois octets de nombres binaires, du code machine (hexadécimal) suivi par ces trois octets convertis en hexadécimal (0x83, 0xC3, 0x0A), puis le mot Assembleur suivi  de "add ebx, 10". L''assembleur et le code machine sont colorés pour expliciter le fait que chaque octet du code machine devient un mot de l''assembleur' width='935' height='505' />

> Une note : les instructions ne sont pas toujours représentées 1 pour 1 en code machine. Par exemple, `add eax, 512` devient `05 00 02 00 00`.
> 
> Le premier octet (`05`) qui veut exactement dire *ajouter le registre EAX à un un nombre 32-bits*. Les octets restants représentent 512 (`0x200`) en ordre [little-endian](https://fr.wikipedia.org/wiki/Boutisme).
>
> Defuse Security a créé [un outil pratique](https://defuse.ca/online-x86-assembler.htm) pour s'amuser avec la traduction entre assembleur et langage machine.

La RAM est la mémoire de votre ordinateur, un grand espace multi-usage qui stocke toutes les données utilisées par les programmes qui tournent dessus. Ça comprend le code des programmes en question, mais aussi le code au cœur de votre système d'exploitation. Le CPU lit toujours le code machine directement dans la RAM, et du code ne peut pas être exécuté s'il n'est pas chargé dans la RAM.

Le CPU stocke un *pointeur d'instruction* qui pointe vers l'emplacement en RAM où il va aller chercher (*fetch* en anglais) la prochaine instruction. Après avoir exécuté une instruction, le CPU bouge le pointeur et recommence. On appelle ça le *cycle d'instruction* (*fetch-execute cycle* en anglais).

<img src='/images/fetch-execute-cycle.png' loading='lazy' style='max-width: 360px; margin: 0 auto;' alt='Un diagramme expliquant le cycle d''instruction. Il y a deux bulles de texte. La première est légendée "Fetch" et contient le texte "Lire l''instruction en mémoire à l''emplacement du pointeur d''instruction". La seconde est légendée "Execute" et contient le texte "Exécuter l''instruction, et déplacer le pointeur d''instruction". La bulle "Fetch" a une flèche qui pointe vers la bulle "Execute", et la bulle "Execute" a une flèche qui re-pointe vers la bulle "Fetch", induisant un processus répétitif' width='848' height='458' />

Après avoir exécuté une instruction, le pointeur se déplace juste après l'instruction en mémoire, afin de pointer vers l'instruction suivante. C'est pour ça que le tourne ! Le pointeur d'instruction ne fait qu'avancer, exécutant du code machine dans l'ordre dans lequel il a été stocké en mémoire. Certaines instructions peuvent dire au pointeur de sauter ailleurs, ou à différents endroits selon une condition; cela permet de ré-utiliser du code ou de mettre en place une logique conditionnelle.

Ce pointeur d'instruction est stocké dans un [*registre*](https://fr.wikipedia.org/wiki/Registre_de_processeur). Les registres sont de petits espaces de stockage dans lesquels le CPU peut très rapidement lire et écrire. Chaque architecture CPU a un nombre défini de registres, utilisés pour un tas de choses allant du stockage de valeurs temporaires pendant un calcul à la configuration du processeur.

Certains de ces registres peuvent être lus directement depuis du code machine, comme `ebx` dans notre diagramme précédent.

D'autres registres sont uniquement utilisés en interne par le CPU, mais peuvent souvent être mis à jour ou lus en utilisant des instructions spéciales. On peut par exemple citer le pointeur d'instruction, qui ne peut pas être directement lu mais peut être mis a jour par exemple par une instruction de saut.

## Les processeurs sont naïfs

Revenons-en à notre question de base : qu'est-ce qui se passe lorsqu'on exécute un programme sur son ordinateur ? D'abord, il se passe des trucs pour se préparer à l’exécuter - on y reviendra - mais à la fin de ce processus on a du code machine dans un fichier quelque part. Le système d'exploitation le charge quelque part en mémoire et demande au CPU de déplacer le pointeur d'instruction de ce déplacer à cet endroit dans la RAM. Le processeur continue alors son cycle d'instruction, le programme commence à s’exécuter!

(C'était un des moments prise de tête pour moi — sérieux, c'est comme ça que le programme que vous utilisez pour lire cet article tourne ! Votre processeur récupère les instructions de votre navigateur dans la RAM à la suite et les exécute, et votre navigateur affiche cet article.)

<img src='/images/instruction-pointer.png' loading='lazy' style='max-width: 400px;' alt='Un diagramme montrant une série d''octets de code machine en RAM. Un octet mis en valeur est indiqué par une flèche légendée "Pointeur d''instruction", et des flèches montrent comment le pointeur d''instruction se déplace en mémoire' width='935' height='372' />

Il se trouve que les CPU ont une vue super basique de leur environnement; ils ne voient que le pointeur d'instructions et un peu de leur état interne. Les processus (*process* en anglais) sont de pures abstractions du système d'exploitation, et non pas quelque chose que les CPU peuvent comprendre ou suivre.

*\*grands gestes\* les process sont des abstractions créées par les ~~développeurs de systèmes d'exploitations~~ grosses boites d'informatique pour vendre plus de machines*

Pour moi, ça pose plus de questions que ça n'en résous :

1. Si le CPU ne connait pas le concept de multiprocess et se contente d'exécuter des instruction de façon séquentielle, comment il fait pour ne pas rester coincé dans un programme ? Comment plusieurs programmes peuvent s’exécuter en même temps ?
2. Si les programmes s'exécutent directement sur le CPU, et si le CPU peut directement accéder à la RAM, pourquoi du code ne peut pas accéder à la zone mémoire d’un autre programme, ou dieu nous en garde, au kernel?
3. Et au fait, c'est quoi le mécanisme qui empêche les process d'exécuter n’importe-quoi et de faire ce qu’ils veulent à votre ordinateur? ET C'EST QUOI UN PUTAIN DE SYSCALL?

La question sur la mémoire mérite sa propre section, et est traitée dans le [chapitre 5](/the-translator-in-your-computer) — en gros, la plupart des accès mémoire passent par une couche de redirection qui réaffecte la totalité de l'espace d'adressage. Pour l'instant, on va faire semblant de croire que les programmes ont accès à toute la RAM, et que les ordinateurs ne peuvent exécuter qu'un programme à la fois. On reviendra sur ces deux suppositions en temps venu.

C'est l'heure de sauter dans notre premier puits sans fond pour arriver dans un mode plein de syscalls et d'anneaux de protection.

> **Note : au fait, c'est quoi un kernel ?**
> 
> Le système d'exploitation de votre ordinateur, comme macOS, Windows ou Linux, est la totalité des programmes qui tournent sur votre ordinateur et font marcher les trucs de base. "Les trucs de base" est un terme très générique, au même titre que "système d'exploitation" — selon à qui vous posez la question, ça peut inclure des choses comme les applis, les polices et les icônes qui viennent par défaut avec votre ordinateur.
>
> Le kernel en revanche est le cœur de votre système d'exploitation. Quand vous démarrez votre ordinateur ,le pointeur d'instruction démarre à l'emplacement d'un programme quelque part. Ce programme, c'est le kernel. Il a presque tous les accès à la mémoire, aux périphériques et à d'autres ressources de votre ordinateur, et a pour tâche de faire tourner les autres programmes installés sur votre ordinateur (qu'on appelle les programmes userland). On verra comment le kernel peut avoir ces accès — et comment les programmes userland ne peuvent pas — au long de cet article.
>
> Linux est juste un kernel et a besoin de plein de programmes userland comme des shells et des serveurs d'affichage pour être utilisable. Le kernel de macOS s'appelle [XNU](https://fr.wikipedia.org/wiki/XNU) et est un Unix-like. Le kernel moderne de Windows s'appelle le [NT Kernel](https://fr.wikipedia.org/wiki/Architecture_de_la_gamme_d%27OS_Windows_NT).

## Deux Anneaux pour les Gouverner Tous

Le *mode* (parfois appelé niveau de privilège ou anneau de protection) dans lequel se trouve un processeur définit ce qu'il a le droit de faire. Les architectures modernes disposend d'au moins deux options: le mode kernel ou supervisor (kernel mode en anglais) et le mode utilisateur (user mode en anglais). Bien qu'une architecture puisse disposer de plus de deux modes, seuls les modes kernel et user sont couramment utilisés de nos jours.

En mode kernel, c'est la fête à la saucisse : le CPU est autorisé à exécuter n'importe-quelle instruction supportée et accéder à n'importe-quelle partie de la mémoire. En mode utilisateur, seul un groupe d'instructions est autorisé, l'accès aux entrées/sorties et à la mémoire est limité, et beaucoup de paramètres du processeur sont verrouillés. Généralement, le kernel et les drivers tournent en mode kernel, alors que les applis sont en mode utilisateur.

Le processeur démarre en mode kernel. Avant d’exécuter un programme, le kernel déclenche le basculement en mode utilisateur.

<img src='/images/kernel-mode-vs-user-mode.png' loading='lazy' style='max-width: 500px; margin: 0 auto;' alt='Deux faux screenshots iMessage montrent les différences entre les protections user mode et kernel mode. Le premier, légendé Kernel Mode : la bulle de droite dit "Lis cette zone mémoire protégée !", la bulle gauche répond "Ok mon lapin :)". Le deuxième, légendé User Mode : la bulle de droite dit "Lis cette zone mémoire protégée !", la bulle de gauche répond :"Non ! Erreur de segmentation !' width='1072' height='433' />

Un exemple de comment les modes du processeur se manifestent dans une vraie architecture : sur x86-64, le niveau de privilège courrant (CPL, current privilege level en anglais) peut être lu dans un registre nommé `cs` (code segment). De manière plus spécifique, le CPL est contenu dans les deux bits de [poids faible](https://fr.wikipedia.org/wiki/Num%C3%A9rotation_des_bits) di registre `cs`. Ces deux bits peuvent stocker l'un des quatre anneaux de sécurité possible de x86-64 : l'anneau 0 est le mode kernel, et le 3 est le mode utilisateur. Les anneaux 1 et 2 sont utilisés pour exécuter des drivers, mais ne sont plus utilisés que par quelques vieux systèmes d'exploitations très spécifiques. Si les bits du CPL sont à `11` par exemple, le CPU utilise l'anneau 3 : mode utilisateur.
 
## C'est quoi un syscall ?

Les programmes tournent en mode utilisateur parce qu'on ne peut pas leur faire assez confiance pour leur donner un accès complet à l'ordinateur. Le mode utilisateur fait son taff en leur empêchant l'accès à la majeure partie de l'ordinateur — mais les programmes ont besoin de pouvoir accéder aux entrées/sorties, allouer de la mémoire et interagir avec le système d'exploitation *d'une manière ou d'une autre* ! Pour ce faire, les logiciens qui tournent en mode utilisateur doivent demander de l'aide au kernel. L'OS peut alors implémenter ses propres mécanismes de protection pour empêcher les programmes de faire quoi que ce soit de malveillant.

Si vous avez déjà écrit du code qui interagit avec l'OS, vous allez certainement reconnaitre des fonctions comme `open`, `read`, `fork` et `exit`. Après un certain nombre de couches d'abstractions, ces fonctions utilisent tous des *appels système* (system calls en anglais, ou syscalls) pour demander de l'aide à l'OS. Un appel système est une procédure spéciale qui permet à un programme de passer de l'espace utilisateur à l'espace kernel, en sautant du code du programme au code de l'OS.

Le passage de l'espace kernel à l'espace utilisateur sont effectués grâce à une fonctionnalité du processeur appelée [interruptions](https://fr.wikipedia.org/wiki/Interruption_(informatique))

1. Pendant le processus de démarrage, le système d'exploitation stocke un tableau qu'on appelle une [Table de Vecteurs d'interruption](https://en.wikipedia.org/wiki/Interrupt_vector_table)(abbrégé *IVT*, x86-64 appelle ça une [Interrupt descriptor table](https://fr.wikipedia.org/wiki/Interrupt_Descriptor_Table)) en RAM et l'enregistre auprès du CPU. L'IVT établit la correspondance entre des numéros d'interruption et des pointeurs vers des cases mémoire.

  <img src='/images/interrupt-vector-table.png' loading='lazy' style='max-width: 300px; margin: 0 auto;' alt='A image of a table captioned "Interrupt Vector Table". The first column, labeled with a number sign, has a series of numbers starting at 01 and going to 04. The corresponding second column of the table, labeled "Handler Address", contains a random 8-byte-long hex number per entry. The bottom of the table has the text "So on and such forth..."' width='555' height='463' />

2. Ensuite, les programmes userland peuvent utiliser une instruction comme [INT](https://www.felixcloutier.com/x86/intn:into:int3:int1) qui demande au processeur de chercher le numéro d'interrupt dans l'IVT, basculer en mode kernel, et bouger le pointeur d'instruction à l'adresse mémoire stockée dans l'IVT..

Quand ce code kernel a été exécuté, il utilise une instruction comme [IRET](https://www.felixcloutier.com/x86/iret:iretd:iretq) pour demander au CPU de re-basculer en mode utilisateur et de re-déplacer le pointeur d'instruction où il était avant le début de l'interruption.

(Si vous êtes curieux, l'identificateur d'interruption pour les appels système sur Linux est `0x80`. Vous pouvez lire une liste des appels système Linux sur le site de [Michael Kerrisk](https://man7.org/linux/man-pages/man2/syscalls.2.html).)

### APIs wrappers : abstraire les interruptions

Voilà ce que l'on  sait pour l'instant des appels système :

- Les programmes en mode utilisateur ne peuvent pas accéder aux entrées/sorties ou à la mémoire directement. Ils doivent d'abord demander de l'aide au système d'exploitation afin d'interagir avec le mode extérieur.
- Les programmes peuvent déléguer du contrôle au système d'exploitation avec des instructions machine spéciales comme INT et IRET.
- Les programmes ne peuvent pas directement changer de niveau de privilège; les interruptions logicielles sont sures parce que le processeur a été préconfiguré *par le système d'exploitation* pour savoir où sauter dans le code de l'OS. L'IVT ne peut être configurée qu'en mode kernel.

Les programmes doivent passer des données au système d'exploitation quand ils déclenchent un appel système; l'OS doit savoir exactement quel appel système exécuter et de quelles données cet appel a besoin, par exemple, le nom du fichier à ouvrir. Les mécanismes pour faire passer ces données varient d'un système d'exploitation et d'une architecture à l'autre, mais il s'agit généralement de placer des données dans certains registres ou sur la pile avant de déclencher une interruption.

Les différentes façons d'effectuer des appels système sur les différents appareils rendrait très difficile pour les développeurs d'implémenter eux-même des appels systèmes pour chaque programme. Ça voudrait aussi dire qu'un système d'exploitation ne pourrait pas changer sa gestion des interruptions de peur de casser tout les programmes ayant été écrits pour une version plus vieille de l'OS. Enfin, on n'écrit généralement plus de programmes en assembleur de nos jours - les programmeurs ne peuvent pas être tenus de taper de l'assembleur dès qu'ils veulent lire un fichier ou allouer de la mémoire.

<img src='/images/syscall-architecture-differences.png' loading='lazy' style='max-width: 650px; margin: 0 auto;' alt='A drawing captioned "System calls are implemented differently across architectures." On the left is a smiling CPU receiving some binary and spitting out a filename, file.txt. Separated on the right is a different CPU receiving the same binary data but with a confused and nauseous facial expression.' width='1057' height='360' />

Les systèmes d'exploitation doivent fournir une couche d'abstraction au dessus de ces interruptions. Des fonctions haut-niveau réutilisables qui enveloppement les instructions en assembleur sont fournies par [libc](https://www.gnu.org/software/libc/) sur les systèmes Unix et font partie d'un librairie nommée [ntdll.dll](https://learn.microsoft.com/fr-fr/windows-hardware/drivers/kernel/libraries-and-headers) sur Windows. Les appels aux fonctions de ces librairies ne déclenchent pas de bascule en mode kernel, il s'agit juste de fonctions standard. Dans ces librairies, du code assembleur passe le contrôle au kernel, et est beaucoup plus spécifique à une plateforme que le code de la librairie qui l'enveloppe.

Quand vous appelez `exit(1)` en C sur un système Unix, cette fonction va en interne exécuter du code qui déclenche une interruption, après avoir placé l'opcode de l'appel système et les arguments dans le bon registre/pile/etc. Les ordinateurs sont tellement cools !

## Need for Speed / CISC

Plein d'architectures [CISC](https://fr.wikipedia.org/wiki/Microprocesseur_%C3%A0_jeu_d%27instruction_%C3%A9tendu) comme x86-64 contiennent des instructions destinées aux appels systèmes à cause de la prévalence du paradigme des appels système.

Intel et AMD se sont débrouillés pour ne pas bien s'accorder sur le x86-64; it contient en fait deux groupes d'instructions d'appels système. [SYSCALL](https://www.felixcloutier.com/x86/syscall.html) et [SYSENTER](https://www.felixcloutier.com/x86/sysenter) sont des alternatives optimisées à des instructions comme `INT 0x80`. Their corresponding return instructions, [SYSRET](https://www.felixcloutier.com/x86/sysret.html) and [SYSEXIT](https://www.felixcloutier.com/x86/sysexit), are designed to transition quickly back to user space and resume program code.

(AMD and Intel processors have slightly different compatibility with these instructions. `SYSCALL` is generally the best option for 64-bit programs, while `SYSENTER` has better support with 32-bit programs.)

Representative of the style, [RISC](https://en.wikipedia.org/wiki/Reduced_instruction_set_computer) architectures tend not to have such special instructions. AArch64, the RISC architecture Apple Silicon is based on, uses only [one interrupt instruction](https://developer.arm.com/documentation/ddi0596/2021-12/Base-Instructions/SVC--Supervisor-Call-) for syscalls and software interrupts alike. I think Mac users are doing fine&nbsp;:)

---

Whew, that was a lot! Let's do a brief recap:

- Processors execute instructions in an infinite fetch-execute loop and don't have any concept of operating systems or programs. The processor's mode, usually stored in a register, determines what instructions may be executed. Operating system code runs in kernel mode and switches to user mode to run programs.
- To run a binary, the operating system switches to user mode and points the processor to the code's entry point in RAM. Because they only have the privileges of user mode, programs that want to interact with the world need to jump to OS code for help. System calls are a standardized way for programs to switch from user mode to kernel mode and into OS code.
- Programs typically use these syscalls by calling shared library functions. These wrap machine code for either software interrupts or architecture-specific syscall instructions that transfer control to the OS kernel and switch rings. The kernel does its business and switches back to user mode and returns to the program code.

Let’s figure out how to answer my first question from earlier:

> If the CPU doesn't keep track of more than one process and just executes instruction after instruction, why doesn't it get stuck inside whatever program it's running? How can multiple programs run at once?

The answer to this, my dear friend, is also the answer to why Coldplay is so popular... clocks! (Well, technically timers. I just wanted to shoehorn that joke in.)
